# -*- coding: utf-8 -*-
"""Modelo Hibrido.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YzpZIMy_cjaRppK2mEvpXuitwjEwejde
"""

!pip install tensorflow

!pip install yfinance

import math
import yfinance as yf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.optimizers import Adam as AdamLegacy
from keras.models import Sequential
from keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
import random
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.dates as mdates
pd.options.mode.chained_assignment = None

ativo = "PETR4.SA"
# ativo = "MGLU3.SA"
inicio = "2017-12-31"
final = "2023-07-22"

dados = yf.download(ativo, inicio, final)

cotacao = dados['Close'].to_numpy().reshape(-1, 1)

tamanho_dados_treinamento = int(len(cotacao) * 0.8)

escalador = MinMaxScaler(feature_range=(0, 1))

treinamento = escalador.fit_transform(cotacao[:tamanho_dados_treinamento, :])
teste = escalador.transform(cotacao[tamanho_dados_treinamento:, :])

dadosMinMax = np.concatenate((treinamento, teste), axis=0)

dados_para_treinamento = dadosMinMax[:tamanho_dados_treinamento, :]

treinamento_x = []
treinamento_y = []
dias_previsao = 60

for i in range(dias_previsao, len(dados_para_treinamento)):
    treinamento_x.append(dados_para_treinamento[i - dias_previsao: i, 0])
    treinamento_y.append(dados_para_treinamento[i, 0])

treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)
treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)

def evaluate_fitness(chromosome):
    # Definir os parâmetros da rede com base no cromossomo
    hidden_units = int(chromosome[0])
    dense = chromosome[1]
    learning_rate = chromosome[2]
    num_epochs = int(chromosome[3])

    print(hidden_units, dense, learning_rate, num_epochs)

    model = Sequential()
    model.add(LSTM(hidden_units, return_sequences=True, input_shape=(treinamento_x.shape[1], 1)))
    model.add(LSTM(hidden_units, return_sequences=False))
    model.add(Dropout(0.5)) # Dropout adicionado com taxa de 0.5
    model.add(Dense(hidden_units/2)) # Função de ativação relu adicionada
    model.add(Dense(1)) # Camada de saída com ativação linear

    # Treinar o modelo
    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))
    model.fit(treinamento_x, treinamento_y, batch_size=32, epochs=1)

    dados_teste = dadosMinMax[tamanho_dados_treinamento - dias_previsao: , :]

    teste_x = []
    teste_y = cotacao[tamanho_dados_treinamento:, :]

    for i in range(dias_previsao, len(dados_teste)):
        teste_x.append(dados_teste[i-dias_previsao: i, 0])

    teste_x = np.array(teste_x)
    teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1])

    predicoes = model.predict(teste_x)
    predicoes = escalador.inverse_transform(predicoes)

    rmse = np.sqrt(np.mean(predicoes - teste_y)**2)
    return rmse



def select_parents(fitness_values):
    # Seleciona dois pais aleatórios com base na probabilidade proporcional ao valor de fitness
    total_fitness = np.sum(fitness_values)
    probabilities = fitness_values / total_fitness
    parents_indices = np.random.choice(len(fitness_values), size=2, replace=False, p=probabilities)
    return parents_indices

def reproduce(parents, population_size, mutation_rate):
    # Cruzamento dos pais
    offspring = []
    for _ in range(population_size):
        child = []
        for j in range(len(parents[0])):
            gene = np.random.choice(parents.shape[0])
            child.append(parents[gene][j])
        offspring.append(child)

        # Mutação
    for i in range(population_size):
        if np.random.rand() < mutation_rate:
            gene = np.random.randint(len(offspring[0]))
            offspring[i][gene] += np.random.normal(0, 0.1)

    return offspring

# Definir os parâmetros do algoritmo genético
num_genes = 4  # O número de genes é igual ao número total de pesos na rede neural
population_size = 4              # Tamanho da população
mutation_rate = 0.05              # Taxa de mutação
num_generations = 4             # Número de gerações

#-------------------------------------------------
def individual():
    hidden_units = random.randint(45, 60)
    dense = random.randint(25, 50)
    learning_rate = random.uniform(0.001, 0.01)
    num_epochs = random.randint(10, 100)
    return [hidden_units, dense, learning_rate, num_epochs]

def generate_population(n_de_individuos):
    return [individual() for _ in range(n_de_individuos)]
#-------------------------------------------------
population = generate_population(population_size)  # Populacao inicial 10


# Executar o algoritmo genético para avaliar a aptidão de cada indivíduo na população
for generation in range(num_generations):
    print(f'Generation {generation + 1}:')
    fitness_values = np.array([evaluate_fitness(chromosome) for chromosome in population])
    best_fitness = np.min(fitness_values)
    print(f'Generation {generation + 1}: best fitness = {best_fitness:.4f}')

    # Selecionar os pais para cruzamento
    parents_indices = select_parents(fitness_values)
    parents = np.array([population[i] for i in parents_indices])

    # Gerar nova população por cruzamento e mutação
    offspring = reproduce(parents, population_size, mutation_rate)

    # Avaliar a aptidão dos filhos gerados
    offspring_fitness_values = np.array([evaluate_fitness(child) for child in offspring])

    # Substituir a população atual pelos filhos gerados
    combined_population = np.vstack((population, offspring))
    combined_fitness_values = np.hstack((fitness_values, offspring_fitness_values))
    sorted_indices = np.argsort(combined_fitness_values)
    sorted_indices = np.argsort(fitness_values)
    population = [combined_population[i] for i in sorted_indices[:population_size]]

# Treinar o modelo final usando a melhor solução encontrada pelo algoritmo genético
best_solution = population[0]


# Definir os parâmetros da rede com base na melhor solução encontrada
hidden_units = int(best_solution[0])
dense = best_solution[1]
learning_rate = best_solution[2]
num_epochs = int(best_solution[3])

print(hidden_units, dense, learning_rate, num_epochs)


model = Sequential()
model.add(LSTM(hidden_units, return_sequences=True, input_shape=(treinamento_x.shape[1], 1)))
model.add(LSTM(hidden_units, return_sequences=False))
model.add(Dropout(0.5)) # Dropout adicionado com taxa de 0.5
model.add(Dense(hidden_units/2)) # Função de ativação relu adicionada
model.add(Dense(1)) # Camada de saída com ativação linear

# Treinar o modelo
model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))
model.fit(treinamento_x, treinamento_y, batch_size=1, epochs=10)

dados_teste = dadosMinMax[tamanho_dados_treinamento - dias_previsao:, :]
teste_x = []

for i in range(dias_previsao, len(dados_teste)):
    teste_x.append(dados_teste[i - dias_previsao: i, 0])

teste_x = np.array(teste_x)
teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)

predicoes = model.predict(teste_x)
predicoes = escalador.inverse_transform(predicoes)

rmse = np.sqrt(np.mean((predicoes - cotacao[tamanho_dados_treinamento:, :]) ** 2))
mse = np.mean((predicoes - cotacao[tamanho_dados_treinamento:, :]) ** 2)
media_y = np.mean(cotacao[tamanho_dados_treinamento:, :])
ss_total = np.sum((cotacao[tamanho_dados_treinamento:, :] - media_y) ** 2)
ss_residual = np.sum((predicoes - cotacao[tamanho_dados_treinamento:, :]) ** 2)
r2 = 1 - (ss_residual / ss_total)
mape = np.mean(np.abs((cotacao[tamanho_dados_treinamento:, :] - predicoes) / cotacao[tamanho_dados_treinamento:, :])) * 100

print("RMSE:", rmse)
print("MSE:", mse)
print("R²:", r2)
print("MAPE:", mape)

treinamento = dados.iloc[:tamanho_dados_treinamento, :]
df_teste = pd.DataFrame({"Close": dados['Close'].iloc[tamanho_dados_treinamento:],
                         "predicoes": predicoes.reshape(len(predicoes))})

plt.figure(figsize=(16, 8))
plt.title("Modelo")
plt.xlabel('Data', fontsize=18)
plt.ylabel("Preço de fechamento", fontsize=18)
plt.plot(treinamento['Close'])
plt.plot(df_teste[['Close', 'predicoes']])
plt.legend(['Treinamento', 'Real', 'Predições'], loc=2, prop={"size": 16})
plt.show()


df_teste.sort_index()

df_teste

#o preço é Legal, mas o importante é acertar pra qual mercado o Lado vai. Sera q isso foi feito?
#calcular media de acertos e expectativa de Lucro

df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()
df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()

df_teste = df_teste.dropna()

df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0, True, False)

df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0, True, False)

df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero'], True, False)

df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()

df_teste

acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])
errou_lado = 1 - acertou_lado

media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()

exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado

ganho_sobre_perda = media_lucro[1]/media_lucro[0]

print(media_lucro)

print(ganho_sobre_perda)
print(errou_lado)
print(acertou_lado)
print(exp_mat_lucro * 100)

# Definir o cash inicial
cash_inicial = 100
cash = cash_inicial

# Lógica de negociação
def realizar_negociacao(df_teste, cash_inicial):
    lucro = 0
    ativo_em_maos = False
    preco_compra = 0
    taxa_transacao = 0.001  # 0,1% de taxa de transação

    df_teste['posicao'] = 0  # Adicionando a coluna 'posicao' inicialmente com valor zero

    for i in range(1, len(df_teste)):
        if df_teste['predicoes'][i] > df_teste['Close'][i - 1] and not ativo_em_maos:
            # Comprar o ativo
            ativo_em_maos = True
            preco_compra = df_teste['Close'][i]
            df_teste.at[df_teste.index[i], 'posicao'] = 1  # Marcar o ponto de compra com 1
            cash_inicial -= (1 + taxa_transacao) * preco_compra
        elif df_teste['predicoes'][i] <= df_teste['Close'][i - 1] and ativo_em_maos:
            # Vender o ativo
            ativo_em_maos = False
            preco_venda = df_teste['Close'][i]
            df_teste.at[df_teste.index[i], 'posicao'] = -1  # Marcar o ponto de venda com -1
            cash_inicial += (1 - taxa_transacao) * preco_venda

    if ativo_em_maos:
        # Caso ainda tenha o ativo em mãos no último dia
        df_teste.at[df_teste.index[-1], 'posicao'] = -1  # Marcar o ponto de venda com -1
        cash_inicial += (1 - taxa_transacao) * df_teste['Close'].iloc[-1]

    lucro = cash_inicial - 100000
    return lucro

lucro_simulado = realizar_negociacao(df_teste, cash_inicial)
cash_total = cash_inicial + lucro_simulado

# ... (código para imprimir o lucro simulado e o cash total) ...

# Gráfico com os pontos de compra e venda destacados
plt.figure(figsize=(16, 8))
plt.title("Modelo")
plt.xlabel('Data', fontsize=18)
plt.ylabel("Preço de fechamento", fontsize=18)
plt.plot(treinamento['Close'], label='Treinamento')
plt.plot(df_teste[['Close', 'predicoes']], label=['Real', 'Predições'])
plt.scatter(df_teste.index[df_teste['posicao'] == 1], df_teste['Close'][df_teste['posicao'] == 1], color='g', label='Compra', marker='^', s=100)
plt.scatter(df_teste.index[df_teste['posicao'] == -1], df_teste['Close'][df_teste['posicao'] == -1], color='r', label='Venda', marker='v', s=100)
plt.legend(loc=2, prop={"size": 16})
plt.show()